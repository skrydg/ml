{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "while not os.getcwd().endswith('ml'):\n",
    "    os.chdir('..')\n",
    "sys.path.insert(0, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import spacy\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.lang.en import English\n",
    "\n",
    "\n",
    "from libs.nlp.ner.ner import NER\n",
    "from helpers.word2vec.converter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PART_LABEL = 'MAIN_PART_LABEL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"kaggle_problems/tweet_sentiment_extraction/train.csv\")\n",
    "test = pd.read_csv(\"kaggle_problems/tweet_sentiment_extraction/test.csv\")\n",
    "\n",
    "train.dropna(inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.dropna(inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_column(column):\n",
    "    column = column.apply(lambda x: ''.join([i for i in x if (i.isalpha() or i == ' ')]))\n",
    "    column = column.apply(lambda x: re.sub(' +', ' ', x))\n",
    "    \n",
    "    column = column.apply(lambda x: x[1:] if x.startswith(' ') else x)\n",
    "    column = column.apply(lambda x: x[:-1] if x.endswith(' ') else x)\n",
    "    \n",
    "    return column\n",
    "\n",
    "def preprocessing(data):\n",
    "    data.text = preprocessing_column(data.text)\n",
    "    if 'selected_text' in data.columns:\n",
    "        data.selected_text = preprocessing_column(data.selected_text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocessing(train)\n",
    "test = preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return s.split(' ')\n",
    "\n",
    "def get_start_end_words(x):\n",
    "    start_char = x['text'].find(x['selected_text'])\n",
    "    start_word = len(tokenize(x['text'][:start_char + 1])) - 1\n",
    "    \n",
    "    cnt_word = len(tokenize(x['selected_text']))\n",
    "    return start_word, start_word + cnt_word\n",
    "\n",
    "def get_start_end_char(x):\n",
    "    start_char = x['text'].find(x['selected_text'])\n",
    "    end_char = start_char + len(x['selected_text'])\n",
    "    \n",
    "    start_char = x['text'][:start_char].rfind(' ') + 1\n",
    "    if start_char < 0:\n",
    "        start_char = 0\n",
    "        \n",
    "    first_space = x['text'][end_char:].find(' ')\n",
    "    if first_space < 0:\n",
    "        end_char = len(x['text'])\n",
    "    else:\n",
    "        end_char = end_char + first_space\n",
    "    return start_char, end_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_spacy_format(data):\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    spacy_data  = [0] * len(data)\n",
    "    for ind, line in data.iterrows():\n",
    "    #     print(\"-\" * 100)\n",
    "    #     print(ind)\n",
    "        start_word, end_word = get_start_end_char(line)\n",
    "        spacy_data[ind] = (\n",
    "            line['text'], \n",
    "            {\"entities\": [(start_word, end_word, MAIN_PART_LABEL)]}\n",
    "        )\n",
    "    #     nlp = English()\n",
    "    #     tokens = nlp(line['text'])\n",
    "\n",
    "    #     print([t.text for t in tokens])\n",
    "    #     print(line['text'])\n",
    "    #     print(start_word, end_word)\n",
    "    #     print(line['selected_text'])\n",
    "    #     print(spacy.gold.biluo_tags_from_offsets(model.make_doc(line['text']), [(start_word, end_word, MAIN_PART_LABEL)]))\n",
    "    #     print(\"-\" * 100)\n",
    "    return spacy_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for positive\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Created blank 'en' model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:27<00:00, 27.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 32998.37882940023}\n",
      "Saved model to kaggle_problems/tweet_sentiment_extraction/models/ner_positive\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training for negative\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Created blank 'en' model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:25<00:00, 25.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 31012.85184123693}\n",
      "Saved model to kaggle_problems/tweet_sentiment_extraction/models/ner_negative\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training for neutral\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Created blank 'en' model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:35<00:00, 35.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 5013.46814936956}\n",
      "Saved model to kaggle_problems/tweet_sentiment_extraction/models/ner_neutral\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for sentiment in ['positive', 'negative', 'neutral']:\n",
    "    print(\"Training for {}\".format(sentiment))\n",
    "    print(\"-\" * 100)\n",
    "    model = NER()\n",
    "    spacy_train_pos = df_to_spacy_format(train[train['sentiment'] == sentiment])\n",
    "    model.train(spacy_train_pos, n_iter=30)\n",
    "    model.save_model('kaggle_problems/tweet_sentiment_extraction/models/ner_{}'.format(sentiment))\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook kaggle_problems/tweet_sentiment_extraction/baseline.ipynb to script\n",
      "[NbConvertApp] Writing 3580 bytes to kaggle_problems/tweet_sentiment_extraction/baseline.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script kaggle_problems/tweet_sentiment_extraction/baseline.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
