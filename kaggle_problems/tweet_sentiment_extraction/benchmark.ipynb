{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "while not os.getcwd().endswith('ml'):\n",
    "    os.chdir('..')\n",
    "sys.path.insert(0, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from helpers.word2vec.converter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LEN = 50\n",
    "WORD_REPRESENTATION_LEN = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Считывание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"kaggle_problems/tweet_sentiment_extraction/train.csv\")\n",
    "test = pd.read_csv(\"kaggle_problems/tweet_sentiment_extraction/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Описание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24502</th>\n",
       "      <td>a502aadba7</td>\n",
       "      <td>Drinking and smoking is very bad.---but im gro...</td>\n",
       "      <td>is very bad.-</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "24502  a502aadba7  Drinking and smoking is very bad.---but im gro...   \n",
       "\n",
       "       selected_text sentiment  \n",
       "24502  is very bad.-  negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>209de29f24</td>\n",
       "      <td>Doing some test shooting later this afternoon....</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID                                               text sentiment\n",
       "1024  209de29f24  Doing some test shooting later this afternoon....   neutral"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3534 27481\n"
     ]
    }
   ],
   "source": [
    "print(len(test), len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec convertation + save on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[~train['text'].isnull()]\n",
    "test = test[~test['text'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_converter = Converter(tokenizer_type=TokenizerType.tweet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    data = data[~data.isnull()]\n",
    "    sentence_converter.clear_statistic()\n",
    "    vectors, cleared_sentences = sentence_converter.convert_sentences(data)\n",
    "    \n",
    "    unknown_words = np.sum([i for i in sentence_converter.unknown_words.values() if i is not None])\n",
    "    known_words = np.sum([i for i in sentence_converter.known_words.values()if i is not None])\n",
    "\n",
    "    print(\"unknown_words: {}, known_words: {}, persent unknown words: {}\".format( \n",
    "          unknown_words, known_words, unknown_words / (unknown_words + known_words)))\n",
    "    \n",
    "    return np.array([[\n",
    "        [i for i in sentence[word_nmb]] \n",
    "        if word_nmb < len(sentence) and sentence[word_nmb] is not None\n",
    "        else np.zeros(WORD_REPRESENTATION_LEN)\n",
    "        for word_nmb in range(0, MAX_SENTENCE_LEN) \n",
    "    ] for sentence in vectors], dtype=np.float16), cleared_sentences, sentence_converter.unknown_words, sentence_converter.known_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_words: 2, known_words: 86, persent unknown words: 0.022727272727272728\n",
      "float16\n"
     ]
    }
   ],
   "source": [
    "vectors, test_cleared_sentences, test_unknown_words, test_known_words = preprocessing(test['text'])\n",
    "print(vectors.dtype)\n",
    "pickle.dump(vectors, open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/test.pkl', 'wb'))\n",
    "pickle.dump(test_cleared_sentences, open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/test_cleared_sentences.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(test_unknown_words, open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/test_unknown_words.pkl', 'wb'))\n",
    "pickle.dump(test_known_words, open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/test_known_words.pkl', 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_words: 14, known_words: 1184, persent unknown words: 0.011686143572621035\n"
     ]
    }
   ],
   "source": [
    "vectors, train_cleared_sentences, train_unknown_words, train_known_words = preprocessing(train['text'])\n",
    "pickle.dump(vectors, open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/train.pkl', 'wb'))\n",
    "pickle.dump(train_cleared_sentences, open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/train_cleared_sentences.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(train_unknown_words, open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/train_unknown_words.pkl', 'wb'))\n",
    "pickle.dump(train_known_words, open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/train_known_words.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_words: 7, known_words: 679, persent unknown words: 0.01020408163265306\n"
     ]
    }
   ],
   "source": [
    "vectors, train_cleared_sentences, train_unknown_words, train_known_words = preprocessing(train['selected_text'])\n",
    "pickle.dump(vectors, open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/selected_train.pkl', 'wb'))\n",
    "pickle.dump(train_cleared_sentences, open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/selected_train_cleared_sentences.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(train_unknown_words, open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/selected_train_unknown_words.pkl.pkl', 'wb'))\n",
    "pickle.dump(train_known_words, open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/selected_train_known_words.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_known_words = pickle.load(open('kaggle_problems/tweet_sentiment_extraction/pickle_dump/train_known_words', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rebootiness', 1),\n",
       " ('freelesson', 1),\n",
       " ('freistunde', 1),\n",
       " ('#kitchenfire', 1),\n",
       " ('gor-juz', 1),\n",
       " ('yyoouu', 1),\n",
       " ('mounce', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(train_unknown_words.items(), key=lambda x : x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rebootiness', 1),\n",
       " ('freelesson', 1),\n",
       " ('freistunde', 1),\n",
       " ('#kitchenfire', 1),\n",
       " ('gor-juz', 1),\n",
       " ('yyoouu', 1),\n",
       " ('mounce', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sentence_converter.unknown_words.items(), key=lambda x : x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01020408163265306\n"
     ]
    }
   ],
   "source": [
    "unknown_words = np.sum([i for i in sentence_converter.unknown_words.values()])\n",
    "known_words = np.sum([i for i in sentence_converter.known_words.values()])\n",
    "print(unknown_words / (unknown_words + known_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка гипотезы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27480 0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Гипотеза: слова из selected_text образуют подотрезок из text\n",
    "#\n",
    "cnt_true = 0\n",
    "cnt_false = 0\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    if row['selected_text'].lower() in row['text'].lower():\n",
    "        cnt_true += 1\n",
    "    else:\n",
    "        cnt_false += 1\n",
    "print(cnt_true, cnt_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook kaggle_problems/tweet_sentiment_extraction/benchmark.ipynb to script\n",
      "[NbConvertApp] Writing 5344 bytes to kaggle_problems/tweet_sentiment_extraction/benchmark.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script kaggle_problems/tweet_sentiment_extraction/benchmark.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_WORDS = 35\n",
    "\n",
    "# def selected_text_start(x):\n",
    "#     start_char = x['text'].find(x['selected_text'])\n",
    "#     start_word = len(x['text'][:start_char].split())\n",
    "#     borders = np.zeros(MAX_WORDS, dtype=int)\n",
    "#     borders[start_word] = 1\n",
    "#     return borders\n",
    "\n",
    "# def selected_text_end(x):\n",
    "#     end_word = np.where(x['start_word'] == 1)[0][0] + len(x['selected_text'].split()) - 1\n",
    "#     borders = np.zeros(MAX_WORDS, dtype=int)\n",
    "#     borders[end_word] = 1\n",
    "#     return borders\n",
    "\n",
    "# train['start_word'] = train.apply(lambda x: selected_text_start(x), axis=1)\n",
    "# train['end_word'] = train.apply(lambda x: selected_text_end(x), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
